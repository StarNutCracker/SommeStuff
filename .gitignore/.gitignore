import numpy as np
import random


class Machine(object):
    
    def __init__(self,data,parameters):
        self.parameters = parameters
        self.d = []
        for i in data:
            self.d.append(Machine.Psi_fin(Machine.Psi(i[0],i[1],i[2],i[3]),self.parameters))
        self.d = np.asarray(self.d)

    @staticmethod
    def Psi(x0,x1,x2,x3):
        #Defines the initial state
        a1 = np.array([np.cos(np.pi/2*x0),np.sin(np.pi/2*x0)])
        a2 = np.array([np.cos(np.pi/2*x1),np.sin(np.pi/2*x1)])
        a3 = np.array([np.cos(np.pi/2*x2),np.sin(np.pi/2*x2)])
        a4 = np.array([np.cos(np.pi/2*x3),np.sin(np.pi/2*x3)])
        return np.kron(a1,np.kron(a2,np.kron(a3,a4)))
        
    @staticmethod    
    def R(p):
        return np.array([[np.cos(p/2),-np.sin(p/2)],[np.sin(p/2),np.cos(p/2)]])
    @staticmethod
    def Ry(p,parity):
        if parity == 2:
            return np.kron(np.identity(2),Machine.R(p))
        if parity == 1:
            return np.kron(Machine.R(p),np.identity(2))
    @staticmethod
    def A(p1,p2):
        C = np.array([[1,0,0,0],[0,1,0,0],[0,0,0,1],[0,0,1,0]])
        return C@Machine.Ry(p1,1)@Machine.Ry(p2,2)@C
    @staticmethod
    def U(p1,p2,p3,p4,p5,p6):
        return Machine.Ry(p1,1)@Machine.Ry(p2,2)@Machine.A(p3,p4)@Machine.Ry(p5,1)@Machine.Ry(p6,2)
    @staticmethod
    def G1(p1,p2,p3,p4,p5,p6):
        return np.kron(Machine.U(p1,p2,p3,p4,p5,p6),np.identity(4))
    @staticmethod
    def G2(p1,p2,p3,p4,p5,p6):
        return np.kron(np.kron(np.identity(2),Machine.U(p1,p2,p3,p4,p5,p6)),np.identity(2))
    @staticmethod
    def G3(p1,p2,p3,p4,p5,p6):
        return np.kron(np.identity(4),Machine.U(p1,p2,p3,p4,p5,p6))
    @staticmethod
    def Psi_fin(psi,p):
        # calculates the final state
        Psi1 = Machine.G1(p[0],p[1],p[2],p[3],p[4],p[5])@psi
        Psi2 = Machine.G2(p[6],p[7],p[8],p[9],p[10],p[11])@Psi1
        return Machine.G3(p[12],p[13],p[14],p[15],p[16],p[17])@Psi2

    def get_Probability(self):
        #Gives out the probability to measure a 1 in the last Qbit
        probability = []
        z = np.array([0,1])
        o = np.array([1,0])
        b1 = np.kron(z,np.kron(z,np.kron(z,o)))
        b2 = np.kron(z,np.kron(z,np.kron(o,o)))
        b3 = np.kron(z,np.kron(o,np.kron(z,o)))
        b4 = np.kron(z,np.kron(o,np.kron(o,o)))
        b5 = np.kron(o,np.kron(z,np.kron(z,o)))
        b6 = np.kron(o,np.kron(z,np.kron(o,o)))
        b7 = np.kron(o,np.kron(o,np.kron(z,o)))
        b8 = np.kron(o,np.kron(o,np.kron(o,o)))
        basis = np.array([b1,b2,b3,b4,b5,b6,b7,b8])
        for i in self.d:
            p=0
            for k in basis:
                p+=np.dot(i,k)**2
            probability.append(p)
        return np.asarray(probability)


def Loss_function(in_data,parameters,out_data):
    # Want to have L=1 and R=0 for the last bit -> P(L)=1 and P(R)=0 for measuring last bit as 1
    lam = 1./3
    eta = 2
    prob_l_f = Machine(in_data,parameters).get_Probability() # array containing the largest-false probabilities
    prob = prob_l_f.copy() # array containing the probabilities
    for i in range(len(out_data)):
        if out_data[i] == 'L':
            prob_l_f[i] = 1-prob_l_f[i]
        if out_data[i] == 'R':
            prob[i] = 1-prob[i]      
    loss_part = np.maximum((prob_l_f-prob+lam),np.zeros(len(prob)))**eta
    return loss_part.sum()/len(in_data)



def Learning():
    # initialize parameters
    par0 = np.array([random.random()*2*np.pi for i in range(18)])
    v0 = np.zeros(len(par0))
    M = 20 # number of training steps
    n = 30 # size of the training batch
    a = 0.1
    b = 0.05
    A = 1.0
    s = 0.6
    t = 0.3
    gam = 0.9


    # atcual training algorithm
    for k in range(M):
        # set the random batch of data
        in_data_batch = []
        out_data_batch = []
        data = open('data_4qb_train.txt','r')
        data_batch = np.asarray(random.sample(list(data), n))
        for i in data_batch:
            out_data_batch.append(i[0])
            in_data_batch.append([int(i[2])/5,int(i[4])/5,int(i[6])/5,int(i[8])/5])
        in_data_batch = np.asarray(in_data_batch)
        out_data_batch = np.asarray(out_data_batch)
        # algorithm described in paper
        ak = a/((k+1+A)**s)
        bk = b/((k+1)**t)
        delta = np.array([(random.random()) for i in range(18)]) # between [0,1)
        par_p = par0+ak*delta
        par_n = par0-ak*delta
        g=(Loss_function(in_data_batch,par_p,out_data_batch)-Loss_function(in_data_batch,par_n,out_data_batch))/(2*ak)
        v0 =gam*v0-g*bk*delta
        par0 = par0+v0

    return par0




# Make the Data ready for test
in_data_test = []
out_data_test = []
data = open('data_4qb_test.txt','r')
for i in data:
    out_data_test.append(i[0])
    in_data_test.append([int(i[2])/5,int(i[4])/5,int(i[6])/5,int(i[8])/5])
in_data_test = np.asarray(in_data_test)
out_data_test = np.asarray(out_data_test)

prob_test = Machine(in_data_test,Learning()).get_Probability()
prob_test = list(prob_test)
out_data_test = list(out_data_test)
for i in range(len(prob_test)):
    if prob_test[i]>= 0.5:
        prob_test[i] = 'L'
    else:
        prob_test[i] = 'R'
s = 0
for k in range(len(prob_test)):
    if prob_test[k]==out_data_test[k]:
        s+=1
print(s/len(prob_test))



# Zum B us de Date zstriche https://archive.ics.uci.edu/ml/datasets/Balance+Scale
#infile = open('data_4qb.txt','r').readlines()
#with open('output.txt','w') as outfile:
#    for i in infile:
#        if i[0] != 'B':
#            outfile.write(i)
